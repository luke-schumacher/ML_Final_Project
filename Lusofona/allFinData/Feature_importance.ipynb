{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c7aaaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Analyzing Feature Importance for NVDA (Excluding High/Low) ---\n",
      "\n",
      "Feature Importances for NVDA (Target: Close, Excluding High/Low):\n",
      "                        Feature    Importance\n",
      "3                          MA_5  3.890006e-01\n",
      "7                        MA_200  1.668267e-01\n",
      "5                         MA_20  1.407408e-01\n",
      "4                         MA_10  1.272775e-01\n",
      "6                         MA_50  1.240366e-01\n",
      "23               price_to_sales  2.870882e-02\n",
      "21                     PE_ratio  2.279946e-02\n",
      "22  days_since_financial_update  3.930435e-04\n",
      "11               volatility_10d  3.218939e-05\n",
      "12               volatility_20d  2.687406e-05\n",
      "13                  momentum_5d  2.306689e-05\n",
      "10                volatility_5d  2.164989e-05\n",
      "8                           RSI  1.765938e-05\n",
      "15                 momentum_20d  1.509292e-05\n",
      "20               netIncomeRatio  1.367631e-05\n",
      "14                 momentum_10d  1.128664e-05\n",
      "17                  volume_ma_5  1.068714e-05\n",
      "19                      revenue  9.379734e-06\n",
      "2                  price_change  7.899727e-06\n",
      "0                        Volume  7.681781e-06\n",
      "9                       returns  6.788793e-06\n",
      "1              price_change_pct  6.283887e-06\n",
      "16                volume_change  6.027165e-06\n",
      "18                          eps  2.575963e-07\n",
      "\n",
      "Feature importance plot saved as 'NVDA_feature_importance_plot_no_high_low.png'\n",
      "\n",
      "Script finished.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "def analyze_stock_feature_importance(file_path, stock_ticker):\n",
    "    \"\"\"\n",
    "    Performs feature importance analysis for a given stock dataset,\n",
    "    excluding 'High' and 'Low' prices from features.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file for the stock.\n",
    "        stock_ticker (str): The ticker symbol of the stock (e.g., 'TSLA').\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Analyzing Feature Importance for {stock_ticker} (Excluding High/Low) ---\")\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}\")\n",
    "        return\n",
    "\n",
    "    # Convert 'date' column to datetime objects and set as index\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.set_index('date')\n",
    "\n",
    "    # Define the target variable\n",
    "    target_variable = 'Close'\n",
    "    if target_variable not in df.columns:\n",
    "        print(f\"Error: Target variable '{target_variable}' not found in {file_path}\")\n",
    "        return\n",
    "    y = df[target_variable]\n",
    "\n",
    "    # Define the features to use based on your provided list,\n",
    "    # EXCLUDING 'Close' (target), 'High', and 'Low'.\n",
    "    # 'price_change' is included as it's a valid predictor for 'Close'.\n",
    "    features_to_use = [\n",
    "        'Volume', 'price_change_pct', 'price_change', # Excluded 'Close', 'High', 'Low' here\n",
    "        'MA_5', 'MA_10', 'MA_20', 'MA_50', 'MA_200',\n",
    "        'RSI', 'returns',\n",
    "        'volatility_5d', 'volatility_10d', 'volatility_20d',\n",
    "        'momentum_5d', 'momentum_10d', 'momentum_20d',\n",
    "        'volume_change', 'volume_ma_5',\n",
    "        'eps', 'revenue', 'netIncomeRatio', 'PE_ratio',\n",
    "        'days_since_financial_update', 'price_to_sales'\n",
    "    ]\n",
    "\n",
    "    # Check if all specified features exist in the DataFrame\n",
    "    missing_features = [f for f in features_to_use if f not in df.columns]\n",
    "    if missing_features:\n",
    "        print(f\"Warning: The following features are missing from {file_path}: {missing_features}\")\n",
    "        # Proceed with available features, or handle as appropriate (e.g., exit)\n",
    "        features_to_use = [f for f in features_to_use if f in df.columns]\n",
    "        if not features_to_use:\n",
    "            print(\"Error: No valid features to use after removing missing ones. Exiting.\")\n",
    "            return\n",
    "\n",
    "    X = df[features_to_use]\n",
    "\n",
    "    # Handle missing values (using mean imputation)\n",
    "    X = X.fillna(X.mean())\n",
    "    y = y.fillna(y.mean()) # Fill NaN in target as well if any\n",
    "\n",
    "    # Scale numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    # Using 80/20 split. Adjust test_size if your dataset is very small.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a RandomForestRegressor model\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Get feature importances\n",
    "    importances = model.feature_importances_\n",
    "\n",
    "    # Create a DataFrame for feature importances\n",
    "    feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "\n",
    "    # Sort by importance in descending order\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    # Display the feature importances as a list\n",
    "    print(f\"\\nFeature Importances for {stock_ticker} (Target: {target_variable}, Excluding High/Low):\")\n",
    "    print(feature_importance_df)\n",
    "\n",
    "    # Plotting the feature importances\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n",
    "    plt.title(f'Feature Importance for {stock_ticker} (Target: {target_variable}, Excluding High/Low)')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot image file\n",
    "    output_filename = f'{stock_ticker}_feature_importance_plot_no_high_low.png'\n",
    "    plt.savefig(output_filename)\n",
    "    print(f\"\\nFeature importance plot saved as '{output_filename}'\")\n",
    "    plt.close() # Close the plot to free memory\n",
    "\n",
    "    return feature_importance_df\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to your TSLA dataset (assuming it's in the same directory)\n",
    "    tsla_file = 'NVDA_merged_dataset_NVDA.csv'\n",
    "    analyze_stock_feature_importance(tsla_file, 'NVDA')\n",
    "\n",
    "    # To analyze other stocks, uncomment and modify the lines below.\n",
    "    # Make sure you have the CSV files in the same directory as this script,\n",
    "    # or provide the full path to the files.\n",
    "\n",
    "    # other_stock_files = {\n",
    "    #     'AAPL': 'AAPL_merged_dataset_AAPL.csv',\n",
    "    #     'MSFT': 'MSFT_merged_dataset_MSFT.csv',\n",
    "    #     'GOOG': 'GOOG_merged_dataset_GOOG.csv',\n",
    "    #     # Add paths for your other 7 stock datasets here\n",
    "    # }\n",
    "\n",
    "    # for ticker, file_path in other_stock_files.items():\n",
    "    #     analyze_stock_feature_importance(file_path, ticker)\n",
    "\n",
    "    print(\"\\nScript finished.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
